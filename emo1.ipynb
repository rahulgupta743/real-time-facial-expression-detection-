{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.applications import VGG16\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fer2013():\n",
    "    data = pd.read_csv('fer2013.csv')\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width,height = 48,48\n",
    "    faces = []\n",
    "    input_shape = (48,48,1)\n",
    "    for sequence in pixels:\n",
    "        face = [int(pixel) for pixel in sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width,height)\n",
    "        face=  cv2.resize(face.astype('uint8'), input_shape[:2])\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces,-1)\n",
    "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "    return faces, emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(x, y, validation_split=.2):\n",
    "    \n",
    "    num_samples = len(x)\n",
    "    num_train_samples = int((1 - validation_split)*num_samples)\n",
    "    train_x = x[:num_train_samples]\n",
    "    train_y = y[:num_train_samples]\n",
    "    val_x = x[num_train_samples:]\n",
    "    val_y = y[num_train_samples:]\n",
    "    train_data = (train_x, train_y)\n",
    "    val_data = (val_x, val_y)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "               use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "               use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "               # kernel_regularizer=regularization,\n",
    "               padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax', name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten , BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/image_data_generator.py:346: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                        featurewise_std_normalization=True,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 46, 46, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 46, 46, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 46, 46, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 44, 44, 8)    576         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 44, 44, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 44, 44, 8)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 44, 44, 16)   200         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 44, 44, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 44, 44, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 44, 44, 16)   400         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 44, 44, 16)   64          separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 22, 22, 16)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 22, 22, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 22, 22, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 22, 22, 16)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 22, 22, 32)   656         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 22, 22, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 22, 22, 32)   1312        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 11, 11, 32)   512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 11, 11, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 11, 11, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 11, 11, 64)   2336        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 11, 11, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 11, 11, 64)   4672        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 6, 6, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 6, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 6, 6, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 6, 6, 128)    8768        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 6, 6, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 6, 6, 128)    17536       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 128)    8192        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 3, 3, 128)    512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 3, 3, 128)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 7)      8071        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 7)            0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape =(48,48,1)\n",
    "model  = mini_XCEPTION(input_shape,7)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "faces , emotions = load_fer2013()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = preprocess_input(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shapes , num_classes = emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35887"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = split_data(faces, emotions, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_faces , train_emotion = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "input_shape = (48, 48, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = emodetect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 124s 1s/step - loss: 1.1164 - acc: 0.5858 - val_loss: 1.1896 - val_acc: 0.5631\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.1310 - acc: 0.5744 - val_loss: 1.1983 - val_acc: 0.5612\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.1097 - acc: 0.5786 - val_loss: 1.4524 - val_acc: 0.4979\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 131s 1s/step - loss: 1.1180 - acc: 0.5792 - val_loss: 1.2078 - val_acc: 0.5598\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 131s 1s/step - loss: 1.1085 - acc: 0.5770 - val_loss: 1.1673 - val_acc: 0.5609\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 136s 1s/step - loss: 1.0983 - acc: 0.5894 - val_loss: 1.1634 - val_acc: 0.5667\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 1.1093 - acc: 0.5864 - val_loss: 1.2080 - val_acc: 0.5532\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 131s 1s/step - loss: 1.1135 - acc: 0.5909 - val_loss: 1.2182 - val_acc: 0.5481\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 138s 1s/step - loss: 1.1238 - acc: 0.5785 - val_loss: 1.1362 - val_acc: 0.5790\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.0867 - acc: 0.5933 - val_loss: 1.1582 - val_acc: 0.5766\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 128s 1s/step - loss: 1.0924 - acc: 0.5958 - val_loss: 1.1772 - val_acc: 0.5734\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0963 - acc: 0.5861 - val_loss: 1.2263 - val_acc: 0.5639\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 128s 1s/step - loss: 1.1001 - acc: 0.5841 - val_loss: 1.2141 - val_acc: 0.5716\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0762 - acc: 0.6001 - val_loss: 1.1916 - val_acc: 0.5549\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0752 - acc: 0.6041 - val_loss: 1.2195 - val_acc: 0.5502\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0858 - acc: 0.5959 - val_loss: 1.1558 - val_acc: 0.5677\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 1.1078 - acc: 0.5872 - val_loss: 1.1293 - val_acc: 0.5840\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.0925 - acc: 0.5878 - val_loss: 1.1434 - val_acc: 0.5692\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0994 - acc: 0.5939 - val_loss: 1.1655 - val_acc: 0.5678\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 124s 1s/step - loss: 1.0852 - acc: 0.5936 - val_loss: 1.1189 - val_acc: 0.5837\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 125s 1s/step - loss: 1.0815 - acc: 0.5961 - val_loss: 1.1045 - val_acc: 0.5900\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0698 - acc: 0.6030 - val_loss: 1.2405 - val_acc: 0.5450\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 1.0636 - acc: 0.6019 - val_loss: 1.1557 - val_acc: 0.5768\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0696 - acc: 0.5992 - val_loss: 1.1591 - val_acc: 0.5692\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0765 - acc: 0.5994 - val_loss: 1.1061 - val_acc: 0.5931\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0796 - acc: 0.5925 - val_loss: 1.1694 - val_acc: 0.5699\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 128s 1s/step - loss: 1.0711 - acc: 0.5918 - val_loss: 1.1387 - val_acc: 0.5821\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.0563 - acc: 0.6067 - val_loss: 1.2104 - val_acc: 0.5699\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 124s 1s/step - loss: 1.0613 - acc: 0.6031 - val_loss: 1.1490 - val_acc: 0.5711\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0623 - acc: 0.6025 - val_loss: 1.1649 - val_acc: 0.5740\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 124s 1s/step - loss: 1.0774 - acc: 0.6020 - val_loss: 1.2368 - val_acc: 0.5626\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 123s 1s/step - loss: 1.0764 - acc: 0.5894 - val_loss: 1.1174 - val_acc: 0.5894\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0566 - acc: 0.5947 - val_loss: 1.1247 - val_acc: 0.5794\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 128s 1s/step - loss: 1.0592 - acc: 0.6053 - val_loss: 1.1190 - val_acc: 0.5770\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 119s 1s/step - loss: 1.0712 - acc: 0.6006 - val_loss: 1.0966 - val_acc: 0.6004\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0469 - acc: 0.6147 - val_loss: 1.1326 - val_acc: 0.5848\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 124s 1s/step - loss: 1.0448 - acc: 0.6058 - val_loss: 1.1263 - val_acc: 0.5901\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0511 - acc: 0.6034 - val_loss: 1.1153 - val_acc: 0.5843\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 125s 1s/step - loss: 1.0575 - acc: 0.5980 - val_loss: 1.0999 - val_acc: 0.5970\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 125s 1s/step - loss: 1.0457 - acc: 0.6078 - val_loss: 1.1879 - val_acc: 0.5658\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 1.0277 - acc: 0.6189 - val_loss: 1.1920 - val_acc: 0.5724\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 1.0410 - acc: 0.6134 - val_loss: 1.1571 - val_acc: 0.5722\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 138s 1s/step - loss: 1.0740 - acc: 0.5972 - val_loss: 1.0916 - val_acc: 0.5949\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 123s 1s/step - loss: 1.0367 - acc: 0.6070 - val_loss: 1.1637 - val_acc: 0.5772\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 125s 1s/step - loss: 1.0742 - acc: 0.6065 - val_loss: 1.1859 - val_acc: 0.5726\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 139s 1s/step - loss: 1.0322 - acc: 0.6080 - val_loss: 1.1544 - val_acc: 0.5762\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 123s 1s/step - loss: 1.0675 - acc: 0.5991 - val_loss: 1.1277 - val_acc: 0.5836\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 1.0312 - acc: 0.6164 - val_loss: 1.0863 - val_acc: 0.6021\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0334 - acc: 0.6097 - val_loss: 1.1329 - val_acc: 0.5780\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 127s 1s/step - loss: 1.0554 - acc: 0.5976 - val_loss: 1.1328 - val_acc: 0.5784\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0256 - acc: 0.6155 - val_loss: 1.2352 - val_acc: 0.5368\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 128s 1s/step - loss: 1.0480 - acc: 0.6036 - val_loss: 1.0989 - val_acc: 0.5942\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 139s 1s/step - loss: 1.0350 - acc: 0.6131 - val_loss: 1.1137 - val_acc: 0.5992\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 127s 1s/step - loss: 1.0361 - acc: 0.6164 - val_loss: 1.1646 - val_acc: 0.5719\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0414 - acc: 0.6072 - val_loss: 1.1049 - val_acc: 0.5961\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0377 - acc: 0.6155 - val_loss: 1.1591 - val_acc: 0.5772\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0172 - acc: 0.6259 - val_loss: 1.0844 - val_acc: 0.6071\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0336 - acc: 0.6148 - val_loss: 1.0802 - val_acc: 0.6042\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0016 - acc: 0.6280 - val_loss: 1.1060 - val_acc: 0.5970\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 1.0369 - acc: 0.6069 - val_loss: 1.0735 - val_acc: 0.6082\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0197 - acc: 0.6205 - val_loss: 1.0858 - val_acc: 0.6045\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0262 - acc: 0.6186 - val_loss: 1.0660 - val_acc: 0.6096\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 139s 1s/step - loss: 1.0212 - acc: 0.6182 - val_loss: 1.1269 - val_acc: 0.5874\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0183 - acc: 0.6159 - val_loss: 1.1380 - val_acc: 0.5864\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 131s 1s/step - loss: 1.0237 - acc: 0.6208 - val_loss: 1.0897 - val_acc: 0.6025\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 131s 1s/step - loss: 1.0310 - acc: 0.6120 - val_loss: 1.1106 - val_acc: 0.5977\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0180 - acc: 0.6248 - val_loss: 1.0779 - val_acc: 0.6080\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0133 - acc: 0.6235 - val_loss: 1.1081 - val_acc: 0.5971\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0031 - acc: 0.6270 - val_loss: 1.0848 - val_acc: 0.5942\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0275 - acc: 0.6108 - val_loss: 1.0931 - val_acc: 0.5986\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 1.0303 - acc: 0.6194 - val_loss: 1.1369 - val_acc: 0.5897\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 1.0259 - acc: 0.6196 - val_loss: 1.1715 - val_acc: 0.5740\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 1.0111 - acc: 0.6300 - val_loss: 1.2282 - val_acc: 0.5588\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 128s 1s/step - loss: 1.0110 - acc: 0.6241 - val_loss: 1.1039 - val_acc: 0.5876\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 0.9988 - acc: 0.6267 - val_loss: 1.1469 - val_acc: 0.5901\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0175 - acc: 0.6213 - val_loss: 1.1153 - val_acc: 0.5911\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 0.9945 - acc: 0.6279 - val_loss: 1.1104 - val_acc: 0.6060\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 136s 1s/step - loss: 0.9960 - acc: 0.6314 - val_loss: 1.1223 - val_acc: 0.5997\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 131s 1s/step - loss: 1.0016 - acc: 0.6291 - val_loss: 1.0870 - val_acc: 0.6018\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0257 - acc: 0.6211 - val_loss: 1.0927 - val_acc: 0.6032\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 1.0097 - acc: 0.6300 - val_loss: 1.0935 - val_acc: 0.6073\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0166 - acc: 0.6205 - val_loss: 1.1970 - val_acc: 0.5690\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 0.9997 - acc: 0.6259 - val_loss: 1.1039 - val_acc: 0.5985\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 137s 1s/step - loss: 0.9910 - acc: 0.6286 - val_loss: 1.1052 - val_acc: 0.5978\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0241 - acc: 0.6162 - val_loss: 1.1084 - val_acc: 0.5919\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 0.9999 - acc: 0.6239 - val_loss: 1.1141 - val_acc: 0.5918\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.0036 - acc: 0.6280 - val_loss: 1.2237 - val_acc: 0.5627\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 122s 1s/step - loss: 1.0127 - acc: 0.6209 - val_loss: 1.0957 - val_acc: 0.5947\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 134s 1s/step - loss: 0.9928 - acc: 0.6247 - val_loss: 1.2730 - val_acc: 0.5364\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 127s 1s/step - loss: 1.0101 - acc: 0.6219 - val_loss: 1.1031 - val_acc: 0.6027\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.9739 - acc: 0.6395 - val_loss: 1.0707 - val_acc: 0.6116\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 1.0076 - acc: 0.6208 - val_loss: 1.0796 - val_acc: 0.5979\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.9767 - acc: 0.6323 - val_loss: 1.0758 - val_acc: 0.6042\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 0.9980 - acc: 0.6230 - val_loss: 1.1292 - val_acc: 0.5938\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 137s 1s/step - loss: 0.9988 - acc: 0.6347 - val_loss: 1.0638 - val_acc: 0.6120\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 133s 1s/step - loss: 0.9965 - acc: 0.6255 - val_loss: 1.0827 - val_acc: 0.6070\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 130s 1s/step - loss: 0.9851 - acc: 0.6258 - val_loss: 1.0969 - val_acc: 0.5940\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.9919 - acc: 0.6325 - val_loss: 1.1130 - val_acc: 0.5993\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.0046 - acc: 0.6257 - val_loss: 1.1689 - val_acc: 0.5651\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 135s 1s/step - loss: 0.9843 - acc: 0.6280 - val_loss: 1.0550 - val_acc: 0.6089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff52e3f7470>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(train_faces, train_emotion,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=100,\n",
    "                        epochs=num_epochs, verbose=1,\n",
    "                        validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mini_xception_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ed003721168f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memotion_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "emotion_classifier.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'mini_xception_model1.hdf5'\n",
    "\n",
    "# hyper-parameters for bounding boxes shape\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
    " \"neutral\"]\n",
    "\n",
    "\n",
    "# starting video streaming\n",
    "cv2.namedWindow('your_face')\n",
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    frame = camera.read()[1]\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=400)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True,\n",
    "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "        (fX, fY, fW, fH) = faces\n",
    "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 48x48 pixels, and then prepare\n",
    "            # the ROI for classification via the CNN\n",
    "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "        roi = cv2.resize(roi, (48, 48))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        \n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "\n",
    " \n",
    "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "                # construct the label text\n",
    "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "                w = int(prob * 300)\n",
    "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
    "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "                (255, 255, 255), 2)\n",
    "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('your_face', frameClone)\n",
    "    cv2.imshow(\"Probabilities\", canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Running setup.py bdist_wheel for imutils: started\n",
      "  Running setup.py bdist_wheel for imutils: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\LENOVO\\AppData\\Local\\pip\\Cache\\wheels\\b2\\40\\59\\139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
